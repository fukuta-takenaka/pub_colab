{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1zH1dYrbVNZ2xfvMew7Bj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fukuta-takenaka/pub_colab/blob/main/tutorial_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像分類実践\n",
        "\n",
        "ページ上部の ランタイム → ランタイムのタイプを変更 → ハードウェアアクセラレータを「GPU」に変更 → 保存  \n",
        "深層学習では、簡単な計算を大量に行い学習を進めます。こういった計算にはGPUが適しています。"
      ],
      "metadata": {
        "id": "R4xyqgNA5VzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### パッケージの準備"
      ],
      "metadata": {
        "id": "ublJpmZ6aAtg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjNaaO6pElys"
      },
      "outputs": [],
      "source": [
        "# 必要なパッケージをインストール\n",
        "# !から始まる行はshell command (Pythonではない)\n",
        "!pip install icrawler\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### webから画像をかき集める：クローリング\n",
        "\n",
        "今回は猫・犬の画像分類器を作成します。猫と犬の画像が必要なので、webからかき集めてきます。収集した画像はランタイムのディスク領域に保存されるため、ランタイムのセッションを閉じると削除されます。"
      ],
      "metadata": {
        "id": "8Knh8-K3aL0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import BingImageCrawler\n",
        "import logging\n",
        "\n",
        "n_img = 200\n",
        "\n",
        "# 猫の画像を取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"cat\"}, log_level=logging.INFO, parser_threads=2, downloader_threads=4,)\n",
        "crawler.crawl(keyword=\"猫\", max_num=n_img)\n",
        "\n",
        "# 犬の画像を取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"dog\"}, log_level=logging.INFO, parser_threads=2, downloader_threads=4,)\n",
        "crawler.crawl(keyword=\"犬\", max_num=n_img)"
      ],
      "metadata": {
        "id": "x0YCoJH3HGBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 収集した画像の読み込み\n",
        "\n",
        "画像をopencv (`cv2`) というモジュールで読み込みます。画像は`numpy`の`np.ndarray`という配列オブジェクトとして読み込まれます。  \n",
        "`ndarray`で気にかけておくべきことは次の3つです。\n",
        "- 配列の次元 = ランク (`ndarray.ndim`)\n",
        "- 配列の形 (`ndarray.shape`)\n",
        "- 配列のデータ型 (`ndarray.dtype`)  \n",
        "\n",
        "一方で中身の個々の値に関しては、大きい配列ですと確認が難しいため、最大値や平均値など配列全体としての情報から期待している数値が入っているか推測することになります。\n",
        "\n",
        "<img src=\"https://qph.fs.quoracdn.net/main-qimg-30be20ab9458b5865b526d287b4fef9a\" width=\"500\" >\n",
        "\n",
        "低次元の配列には名前がついています。\n",
        "- 0次元: スカラー\n",
        "- 1次元: ベクトル\n",
        "- 2次元: マトリックス\n",
        "\n",
        "これらを一般化した概念をテンソルと呼びます。"
      ],
      "metadata": {
        "id": "wxEDbEYZa_mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ダウンロードした画像を全て同じ大きさにリサイズし、メモリに格納\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path  # ディスク上のファイル一覧を取得するなど、パスの操作に用いるモジュール\n",
        "\n",
        "img_size = 64\n",
        "imgs_cat = list()\n",
        "imgs_dog = list()\n",
        "\n",
        "for img_list, img_dir in ((imgs_cat, './cat'), (imgs_dog, './dog')):\n",
        "  # 画像パス一つずつを処理\n",
        "  for impath in Path(img_dir).iterdir():\n",
        "    # 画像読み込み: cv2.imread()\n",
        "    img = cv2.imread(str(impath))\n",
        "    # 画像リサイズ\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img_list.append(img)\n",
        "\n",
        "# listをndarrayに変換\n",
        "imgs_cat = np.array(imgs_cat)\n",
        "imgs_dog = np.array(imgs_dog)\n",
        "\n",
        "# テンソルの情報を確認\n",
        "print(imgs_cat.ndim)\n",
        "print(imgs_cat.shape)\n",
        "print(imgs_cat.dtype)\n",
        "print('')\n",
        "print(imgs_dog.ndim)\n",
        "print(imgs_dog.shape)\n",
        "print(imgs_dog.dtype)"
      ],
      "metadata": {
        "id": "4jzQGLWpHMJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0ae1c9-76cd-4924-bc03-7663c0353194"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "(180, 64, 64, 3)\n",
            "uint8\n",
            "\n",
            "4\n",
            "(151, 64, 64, 3)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cv2.imread()`関数で読み込んだ画像のデータ型は、デフォルトでは`np.uint8`という、符号なし（=マイナスを表現できない）8 bitの整数です。[0, 255]の範囲のみ表現可能です。  \n",
        "`imgs_cat`は4次元配列で形が(n, 64, 64, 3)になっています。これは、最初の軸 (`axis = 0`) には画像の枚数nが、続く3つの次元には64 x 64 pixelの3チャネル (RGB) 画像が格納されているという意味になっています。  \n",
        "(`cv2.imread()`で読み込んだ画像は、厳密にはチャネルの並びがBGRの順番になっています。)"
      ],
      "metadata": {
        "id": "FBylpLMdgqks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 収集した画像の確認\n",
        "\n",
        "読み込んだ画像をタイル状に並べて確認します"
      ],
      "metadata": {
        "id": "XWMFHOzdfu4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像の一覧可視化関数\n",
        "import math\n",
        "import PIL\n",
        "\n",
        "def tile_show(imgs, n_col=10):\n",
        "  h, w = imgs[0].shape[:2]\n",
        "  assert all([img.shape[:2] == (h, w) for img in imgs])\n",
        "  n_row = math.ceil(len(imgs) / n_col)\n",
        "  tile = np.zeros((h*n_row, w*n_col, 3), np.uint8)\n",
        "  for i, img in enumerate(imgs):\n",
        "    row = i // n_col\n",
        "    col = i % n_col\n",
        "    y1 = row * h\n",
        "    y2 = (row+1) * h\n",
        "    x1 = col * w\n",
        "    x2 = (col+1) * w\n",
        "    tile[y1:y2, x1:x2] = img\n",
        "  \n",
        "  return PIL.Image.fromarray(tile[..., ::-1])"
      ],
      "metadata": {
        "id": "xURaDAa1Ss0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tile_show(imgs_cat)"
      ],
      "metadata": {
        "id": "vDsM-SrGLF84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tile_show(imgs_dog)"
      ],
      "metadata": {
        "id": "bAxsHhNRLGyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習データ・テストデータの作成\n",
        "\n",
        "収集した画像を学習用とテスト用（精度評価用）に分け、ラベル（正解）を付与する。  \n",
        "猫=0、犬=1とする。\n",
        "\n",
        "\n",
        "画像処理では、入力画像を少数で[-1, 1]の範囲に正規化して用いることが多い。すなわち、`np.uint8`[0, 255]を`np.float32`[-1, 1]に変換する。"
      ],
      "metadata": {
        "id": "e3xlpcLasYVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データとテストデータの作成\n",
        "test_rate = 0.2\n",
        "n_cat_test = int(len(imgs_cat) * test_rate)\n",
        "n_dog_test = int(len(imgs_dog) * test_rate)\n",
        "\n",
        "cat_test, cat_train = imgs_cat[:n_cat_test], imgs_cat[n_cat_test:]\n",
        "dog_test, dog_train = imgs_dog[:n_dog_test], imgs_dog[n_dog_test:]\n",
        "\n",
        "# ndarrayの結合, dtypeをfloat32に変更, [-1,1]に正規化\n",
        "train_X = np.concatenate([cat_train, dog_train], axis=0).astype(np.float32)\n",
        "train_X = ((train_X / 255.) - 0.5) * 2\n",
        "test_X = np.concatenate([cat_test, dog_test], axis=0).astype(np.float32)\n",
        "test_X = ((test_X / 255.) - 0.5) * 2\n",
        "\n",
        "# 正規化の確認。train_Xに含まれる全画素の輝度のヒストグラム\n",
        "plt.hist(train_X.flatten())\n",
        "\n",
        "# ラベルを作成。猫=0、犬=1として設定\n",
        "train_y = np.array([0.] * len(cat_train) + [1.] * len(dog_train)).astype(np.float32)\n",
        "test_y = np.array([0.] * len(cat_test) + [1.] * len(dog_test)).astype(np.float32)\n"
      ],
      "metadata": {
        "id": "VNthTJOfRiAj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "83b801ef-5e35-4a6c-f2cd-77a2066bb496"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの作成\n",
        "\n",
        "今回はVGG16という畳み込みニューラルネットワークを用います。  \n",
        "有名なモデルはtensorflwoフレームワークに組み込まれており、呼び出すだけでモデルが使用できます。"
      ],
      "metadata": {
        "id": "xMMp8_eYtV2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "vgg = VGG16(include_top=True, weights=None, input_shape=(img_size, img_size, 3), classes=1)\n",
        "vgg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8EbqFbWtq_A",
        "outputId": "db6d9c05-8e83-4622-8ce2-bd31506e45e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              8392704   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,892,801\n",
            "Trainable params: 39,892,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  `tf.keras.Model.summary()`メソッドでは、モデルの各レイヤーのテンソルの形が表示されます (`None`は数値が任意であることを示す) 。モデルを1つの大きな関数として考えた時、重要なのは入力と出力です。  \n",
        "- input:  `input_5 (InputLayer)        [(None, 64, 64, 3)]`  \n",
        "- output:   `predictions (Dense)         (None, 1)`\n",
        "\n",
        "このモデルは、「4次元テンソルを入力されると2次元テンソルを出力する関数」と言えます。さらに、出力の形が`(None, 1)`であるため、実質的には出力を1次元テンソル = ベクトルと考えることができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "n3bHSdeIvcj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ニューラルネットワーク\n",
        "\n",
        "<img src=\"https://www.esector.co.jp/bpa/img/A19-034.png\" width=\"500\">\n",
        "<a href=\"https://www.esector.co.jp/bpa/A19-034.html\">src</a>\n",
        "\n",
        "ニューロンに対応する部分をノードなどと呼ぶ。たいてい1ノードだけで扱うことはなく、層のような構造に例えられるためレイヤーとも呼ばれる\n",
        "\n",
        "<img src=\"https://www.imagazine.co.jp/wp-content/uploads/2018/07/086-090_16ISno13_kiso_deep_zu003.jpg\" width=\"500\">\n",
        "<a href=\"https://www.imagazine.co.jp/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99/\">src</a>\n",
        "\n",
        "畳み込みニューラルネットワーク（CNN）は、神経細胞の発火のルールを、画像の部分領域をベースにしたという点で、人間の視覚処理により近い構造を模していると考えることができる。"
      ],
      "metadata": {
        "id": "XBhfb-gp5SgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 畳み込み処理\n",
        "\n",
        "<img src=\"https://axa.biopapyrus.jp/media/CNN_Conv3.png\" width=\"500\"><a href=\"https://axa.biopapyrus.jp/deep-learning/cnn/convolution.html\">src</a>\n",
        "\n",
        "中央の3x3の配列をfilter, kernel, windowなどと呼ぶ。畳み込みは特定のパターン（模様）を抽出する操作だと考えることもでき、フィルターの内容がパターンを決定する。CNNでは、フィルターの中身を学習によって更新し、学習がうまく進むと画像内の特徴量（猫らしさ、犬らしさの指標になる模様など）が抽出できるようになる。\n",
        "\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/wrxLE.png\" width=\"500\"><a href=\"http://web.pdx.edu/~jduh/courses/Archive/geog481w07/Students/Ludwig_ImageConvolution.pdf\">src</a>  \n",
        "カーネルの違いによる畳み込み効果の例"
      ],
      "metadata": {
        "id": "WRz8y7poD9Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの学習"
      ],
      "metadata": {
        "id": "tTt5DtMu5Whi"
      }
    }
  ]
}